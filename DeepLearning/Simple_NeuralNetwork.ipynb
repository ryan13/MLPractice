{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import numpy as np\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('/home/tri/Downloads/MLdatasets/pima-indians-diabetes.data',delimiter=\",\")\n",
    "X=dataset[:,0:8]\n",
    "y= dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8, kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 1s - loss: 0.6794 - acc: 0.6401 - val_loss: 0.6584 - val_acc: 0.6732\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s - loss: 0.6689 - acc: 0.6401 - val_loss: 0.6534 - val_acc: 0.6732\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s - loss: 0.6603 - acc: 0.6401 - val_loss: 0.6484 - val_acc: 0.6732\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s - loss: 0.6495 - acc: 0.6420 - val_loss: 0.6402 - val_acc: 0.6654\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s - loss: 0.6352 - acc: 0.6440 - val_loss: 0.6281 - val_acc: 0.6654\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s - loss: 0.6265 - acc: 0.6381 - val_loss: 0.6162 - val_acc: 0.6969\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s - loss: 0.6142 - acc: 0.6712 - val_loss: 0.6112 - val_acc: 0.6496\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s - loss: 0.6124 - acc: 0.6634 - val_loss: 0.6060 - val_acc: 0.6339\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s - loss: 0.6021 - acc: 0.6693 - val_loss: 0.6012 - val_acc: 0.6811\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s - loss: 0.5988 - acc: 0.6848 - val_loss: 0.5999 - val_acc: 0.6496\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s - loss: 0.5971 - acc: 0.6673 - val_loss: 0.6059 - val_acc: 0.6339\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s - loss: 0.6022 - acc: 0.6770 - val_loss: 0.5996 - val_acc: 0.6378\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s - loss: 0.5989 - acc: 0.6868 - val_loss: 0.5942 - val_acc: 0.6496\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s - loss: 0.5900 - acc: 0.6907 - val_loss: 0.5912 - val_acc: 0.6614\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s - loss: 0.5924 - acc: 0.6907 - val_loss: 0.5911 - val_acc: 0.6496\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s - loss: 0.5984 - acc: 0.6751 - val_loss: 0.5894 - val_acc: 0.6929\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s - loss: 0.5907 - acc: 0.6926 - val_loss: 0.5874 - val_acc: 0.6535\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s - loss: 0.5861 - acc: 0.6887 - val_loss: 0.5893 - val_acc: 0.6496\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s - loss: 0.5890 - acc: 0.7218 - val_loss: 0.5847 - val_acc: 0.6811\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s - loss: 0.5871 - acc: 0.6926 - val_loss: 0.5858 - val_acc: 0.6378\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s - loss: 0.5882 - acc: 0.6887 - val_loss: 0.5967 - val_acc: 0.6417\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s - loss: 0.5847 - acc: 0.7101 - val_loss: 0.5873 - val_acc: 0.6654\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s - loss: 0.5840 - acc: 0.6848 - val_loss: 0.5820 - val_acc: 0.6732\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s - loss: 0.5746 - acc: 0.7062 - val_loss: 0.5862 - val_acc: 0.6614\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s - loss: 0.5858 - acc: 0.6946 - val_loss: 0.5787 - val_acc: 0.6772\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s - loss: 0.5776 - acc: 0.7101 - val_loss: 0.5834 - val_acc: 0.6693\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s - loss: 0.5801 - acc: 0.7179 - val_loss: 0.5774 - val_acc: 0.6614\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s - loss: 0.5853 - acc: 0.7043 - val_loss: 0.6237 - val_acc: 0.5984\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s - loss: 0.5794 - acc: 0.6926 - val_loss: 0.5825 - val_acc: 0.7165\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s - loss: 0.5762 - acc: 0.7043 - val_loss: 0.5791 - val_acc: 0.6811\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s - loss: 0.5741 - acc: 0.6907 - val_loss: 0.5756 - val_acc: 0.6614\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s - loss: 0.5773 - acc: 0.7043 - val_loss: 0.5962 - val_acc: 0.6654\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s - loss: 0.5831 - acc: 0.7043 - val_loss: 0.5948 - val_acc: 0.6732\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s - loss: 0.5707 - acc: 0.7082 - val_loss: 0.5723 - val_acc: 0.6890\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s - loss: 0.5697 - acc: 0.7179 - val_loss: 0.5811 - val_acc: 0.6654\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s - loss: 0.5794 - acc: 0.7023 - val_loss: 0.5794 - val_acc: 0.6496\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s - loss: 0.5706 - acc: 0.7043 - val_loss: 0.5740 - val_acc: 0.7165\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s - loss: 0.5707 - acc: 0.7023 - val_loss: 0.5714 - val_acc: 0.7008\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s - loss: 0.5729 - acc: 0.6926 - val_loss: 0.5672 - val_acc: 0.7047\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s - loss: 0.5680 - acc: 0.7237 - val_loss: 0.5741 - val_acc: 0.6654\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s - loss: 0.5672 - acc: 0.7160 - val_loss: 0.5705 - val_acc: 0.6693\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s - loss: 0.5655 - acc: 0.7296 - val_loss: 0.5817 - val_acc: 0.7008\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s - loss: 0.5718 - acc: 0.7237 - val_loss: 0.5649 - val_acc: 0.7047\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s - loss: 0.5671 - acc: 0.7121 - val_loss: 0.5702 - val_acc: 0.6772\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s - loss: 0.5615 - acc: 0.7179 - val_loss: 0.6023 - val_acc: 0.6457\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s - loss: 0.5694 - acc: 0.7121 - val_loss: 0.5680 - val_acc: 0.6850\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s - loss: 0.5642 - acc: 0.7101 - val_loss: 0.5690 - val_acc: 0.7205\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s - loss: 0.5661 - acc: 0.7160 - val_loss: 0.5662 - val_acc: 0.7047\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s - loss: 0.5605 - acc: 0.7198 - val_loss: 0.5718 - val_acc: 0.6693\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s - loss: 0.5591 - acc: 0.7335 - val_loss: 0.5773 - val_acc: 0.6929\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s - loss: 0.5552 - acc: 0.7276 - val_loss: 0.5606 - val_acc: 0.7205\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s - loss: 0.5618 - acc: 0.7218 - val_loss: 0.5659 - val_acc: 0.7126\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s - loss: 0.5551 - acc: 0.7160 - val_loss: 0.5614 - val_acc: 0.7165\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s - loss: 0.5558 - acc: 0.7374 - val_loss: 0.5636 - val_acc: 0.7087\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s - loss: 0.5537 - acc: 0.7393 - val_loss: 0.5590 - val_acc: 0.7244\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s - loss: 0.5541 - acc: 0.7276 - val_loss: 0.5864 - val_acc: 0.6811\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s - loss: 0.5558 - acc: 0.7296 - val_loss: 0.5685 - val_acc: 0.6890\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s - loss: 0.5517 - acc: 0.7315 - val_loss: 0.5697 - val_acc: 0.6969\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s - loss: 0.5537 - acc: 0.7315 - val_loss: 0.5598 - val_acc: 0.7165\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s - loss: 0.5497 - acc: 0.7393 - val_loss: 0.5581 - val_acc: 0.7283\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s - loss: 0.5541 - acc: 0.7490 - val_loss: 0.5708 - val_acc: 0.6772\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s - loss: 0.5518 - acc: 0.7315 - val_loss: 0.5623 - val_acc: 0.7165\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s - loss: 0.5466 - acc: 0.7354 - val_loss: 0.5695 - val_acc: 0.6811\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s - loss: 0.5487 - acc: 0.7432 - val_loss: 0.5511 - val_acc: 0.7244\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s - loss: 0.5504 - acc: 0.7315 - val_loss: 0.5590 - val_acc: 0.7087\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.5533 - acc: 0.7335 - val_loss: 0.5587 - val_acc: 0.7126\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s - loss: 0.5465 - acc: 0.7335 - val_loss: 0.5580 - val_acc: 0.7087\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s - loss: 0.5486 - acc: 0.7335 - val_loss: 0.5671 - val_acc: 0.7087\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s - loss: 0.5434 - acc: 0.7296 - val_loss: 0.5513 - val_acc: 0.7283\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s - loss: 0.5458 - acc: 0.7529 - val_loss: 0.5563 - val_acc: 0.7165\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s - loss: 0.5429 - acc: 0.7471 - val_loss: 0.5615 - val_acc: 0.7047\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s - loss: 0.5425 - acc: 0.7393 - val_loss: 0.5482 - val_acc: 0.7323\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s - loss: 0.5505 - acc: 0.7257 - val_loss: 0.5490 - val_acc: 0.7323\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s - loss: 0.5353 - acc: 0.7412 - val_loss: 0.5515 - val_acc: 0.7441\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s - loss: 0.5388 - acc: 0.7451 - val_loss: 0.5566 - val_acc: 0.7205\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s - loss: 0.5431 - acc: 0.7315 - val_loss: 0.5530 - val_acc: 0.7126\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s - loss: 0.5375 - acc: 0.7257 - val_loss: 0.5482 - val_acc: 0.7402\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s - loss: 0.5346 - acc: 0.7490 - val_loss: 0.5453 - val_acc: 0.7441\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s - loss: 0.5425 - acc: 0.7296 - val_loss: 0.5555 - val_acc: 0.7087\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s - loss: 0.5360 - acc: 0.7412 - val_loss: 0.5431 - val_acc: 0.7402\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s - loss: 0.5397 - acc: 0.7490 - val_loss: 0.5516 - val_acc: 0.7165\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s - loss: 0.5316 - acc: 0.7374 - val_loss: 0.5446 - val_acc: 0.7283\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s - loss: 0.5273 - acc: 0.7432 - val_loss: 0.5481 - val_acc: 0.7283\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s - loss: 0.5355 - acc: 0.7412 - val_loss: 0.5426 - val_acc: 0.7480\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s - loss: 0.5308 - acc: 0.7451 - val_loss: 0.5467 - val_acc: 0.7480\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s - loss: 0.5278 - acc: 0.7432 - val_loss: 0.5413 - val_acc: 0.7402\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s - loss: 0.5263 - acc: 0.7490 - val_loss: 0.5463 - val_acc: 0.7402\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s - loss: 0.5253 - acc: 0.7432 - val_loss: 0.5547 - val_acc: 0.7165\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s - loss: 0.5265 - acc: 0.7412 - val_loss: 0.5436 - val_acc: 0.7244\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s - loss: 0.5250 - acc: 0.7529 - val_loss: 0.5448 - val_acc: 0.7402\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s - loss: 0.5262 - acc: 0.7393 - val_loss: 0.5490 - val_acc: 0.7362\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s - loss: 0.5297 - acc: 0.7412 - val_loss: 0.5449 - val_acc: 0.7283\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s - loss: 0.5221 - acc: 0.7549 - val_loss: 0.5423 - val_acc: 0.7480\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s - loss: 0.5271 - acc: 0.7568 - val_loss: 0.5414 - val_acc: 0.7441\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s - loss: 0.5278 - acc: 0.7549 - val_loss: 0.5628 - val_acc: 0.7126\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s - loss: 0.5274 - acc: 0.7335 - val_loss: 0.5416 - val_acc: 0.7402\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s - loss: 0.5212 - acc: 0.7529 - val_loss: 0.5431 - val_acc: 0.7323\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s - loss: 0.5331 - acc: 0.7335 - val_loss: 0.5532 - val_acc: 0.7126\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s - loss: 0.5302 - acc: 0.7451 - val_loss: 0.5421 - val_acc: 0.7598\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s - loss: 0.5246 - acc: 0.7354 - val_loss: 0.5352 - val_acc: 0.7362\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s - loss: 0.5203 - acc: 0.7490 - val_loss: 0.5411 - val_acc: 0.7244\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s - loss: 0.5149 - acc: 0.7568 - val_loss: 0.5331 - val_acc: 0.7598\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s - loss: 0.5249 - acc: 0.7549 - val_loss: 0.5548 - val_acc: 0.7402\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s - loss: 0.5198 - acc: 0.7393 - val_loss: 0.5295 - val_acc: 0.7480\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s - loss: 0.5145 - acc: 0.7471 - val_loss: 0.5284 - val_acc: 0.7559\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s - loss: 0.5204 - acc: 0.7296 - val_loss: 0.5311 - val_acc: 0.7480\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s - loss: 0.5192 - acc: 0.7393 - val_loss: 0.5417 - val_acc: 0.7402\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s - loss: 0.5237 - acc: 0.7588 - val_loss: 0.5276 - val_acc: 0.7598\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s - loss: 0.5148 - acc: 0.7588 - val_loss: 0.5275 - val_acc: 0.7638\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s - loss: 0.5168 - acc: 0.7529 - val_loss: 0.5410 - val_acc: 0.7441\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s - loss: 0.5206 - acc: 0.7529 - val_loss: 0.5306 - val_acc: 0.7480\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s - loss: 0.5058 - acc: 0.7529 - val_loss: 0.5354 - val_acc: 0.7441\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s - loss: 0.5125 - acc: 0.7549 - val_loss: 0.5268 - val_acc: 0.7559\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s - loss: 0.5084 - acc: 0.7626 - val_loss: 0.5308 - val_acc: 0.7480\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s - loss: 0.5135 - acc: 0.7510 - val_loss: 0.5274 - val_acc: 0.7480\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s - loss: 0.5097 - acc: 0.7471 - val_loss: 0.5219 - val_acc: 0.7677\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s - loss: 0.5137 - acc: 0.7568 - val_loss: 0.5308 - val_acc: 0.7559\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s - loss: 0.5070 - acc: 0.7646 - val_loss: 0.5268 - val_acc: 0.7638\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s - loss: 0.5101 - acc: 0.7549 - val_loss: 0.5291 - val_acc: 0.7598\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s - loss: 0.5038 - acc: 0.7607 - val_loss: 0.5257 - val_acc: 0.7559\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s - loss: 0.5096 - acc: 0.7412 - val_loss: 0.5362 - val_acc: 0.7480\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s - loss: 0.5134 - acc: 0.7510 - val_loss: 0.5343 - val_acc: 0.7520\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s - loss: 0.5108 - acc: 0.7451 - val_loss: 0.5394 - val_acc: 0.7283\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s - loss: 0.5067 - acc: 0.7588 - val_loss: 0.5236 - val_acc: 0.7441\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s - loss: 0.5155 - acc: 0.7665 - val_loss: 0.5302 - val_acc: 0.7520\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s - loss: 0.5040 - acc: 0.7412 - val_loss: 0.5423 - val_acc: 0.7244\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s - loss: 0.5014 - acc: 0.7607 - val_loss: 0.5247 - val_acc: 0.7520\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s - loss: 0.4985 - acc: 0.7626 - val_loss: 0.5212 - val_acc: 0.7638\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s - loss: 0.5071 - acc: 0.7510 - val_loss: 0.5289 - val_acc: 0.7441\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s - loss: 0.5034 - acc: 0.7607 - val_loss: 0.5209 - val_acc: 0.7598\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.5030 - acc: 0.7412 - val_loss: 0.5319 - val_acc: 0.7559\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s - loss: 0.5070 - acc: 0.7451 - val_loss: 0.5162 - val_acc: 0.7559\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s - loss: 0.4974 - acc: 0.7704 - val_loss: 0.5155 - val_acc: 0.7835\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s - loss: 0.4985 - acc: 0.7607 - val_loss: 0.5244 - val_acc: 0.7559\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s - loss: 0.4997 - acc: 0.7510 - val_loss: 0.5161 - val_acc: 0.7717\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s - loss: 0.5042 - acc: 0.7432 - val_loss: 0.5170 - val_acc: 0.7520\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s - loss: 0.5061 - acc: 0.7451 - val_loss: 0.5209 - val_acc: 0.7717\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s - loss: 0.4965 - acc: 0.7626 - val_loss: 0.5115 - val_acc: 0.7795\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s - loss: 0.4997 - acc: 0.7646 - val_loss: 0.5197 - val_acc: 0.7677\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s - loss: 0.4939 - acc: 0.7510 - val_loss: 0.5130 - val_acc: 0.7795\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s - loss: 0.4964 - acc: 0.7510 - val_loss: 0.5125 - val_acc: 0.7874\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s - loss: 0.4940 - acc: 0.7607 - val_loss: 0.5217 - val_acc: 0.7835\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s - loss: 0.5077 - acc: 0.7490 - val_loss: 0.5095 - val_acc: 0.7913\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s - loss: 0.5076 - acc: 0.7393 - val_loss: 0.5090 - val_acc: 0.7756\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s - loss: 0.4970 - acc: 0.7607 - val_loss: 0.5083 - val_acc: 0.7795\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s - loss: 0.4975 - acc: 0.7549 - val_loss: 0.5126 - val_acc: 0.7677\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s - loss: 0.4914 - acc: 0.7646 - val_loss: 0.5085 - val_acc: 0.7913\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s - loss: 0.4957 - acc: 0.7607 - val_loss: 0.5135 - val_acc: 0.7795\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s - loss: 0.4955 - acc: 0.7685 - val_loss: 0.5080 - val_acc: 0.7913\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s - loss: 0.4854 - acc: 0.7588 - val_loss: 0.5092 - val_acc: 0.7874\n",
      " 32/768 [>.............................] - ETA: 0sacc: 77.60%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X,y,validation_split=0.33,epochs=150,batch_size=10)\n",
    "scores=model.evaluate(X,y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Well done. A good start! Let go further to experience by specifying data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s - loss: 0.4872 - acc: 0.7802 - val_loss: 0.4990 - val_acc: 0.7717\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s - loss: 0.4787 - acc: 0.7763 - val_loss: 0.5034 - val_acc: 0.7559\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s - loss: 0.4800 - acc: 0.7840 - val_loss: 0.5013 - val_acc: 0.7756\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s - loss: 0.4768 - acc: 0.7724 - val_loss: 0.5028 - val_acc: 0.7717\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s - loss: 0.4755 - acc: 0.7782 - val_loss: 0.5003 - val_acc: 0.7638\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s - loss: 0.4735 - acc: 0.7840 - val_loss: 0.5056 - val_acc: 0.7598\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s - loss: 0.4818 - acc: 0.7724 - val_loss: 0.5179 - val_acc: 0.7441\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s - loss: 0.4989 - acc: 0.7529 - val_loss: 0.5078 - val_acc: 0.7677\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s - loss: 0.4928 - acc: 0.7860 - val_loss: 0.5020 - val_acc: 0.7480\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s - loss: 0.4746 - acc: 0.7782 - val_loss: 0.5071 - val_acc: 0.7480\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s - loss: 0.4828 - acc: 0.7646 - val_loss: 0.5069 - val_acc: 0.7520\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s - loss: 0.4710 - acc: 0.7646 - val_loss: 0.5017 - val_acc: 0.7559\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.4739 - acc: 0.767 - 0s - loss: 0.4752 - acc: 0.7665 - val_loss: 0.5101 - val_acc: 0.7520\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s - loss: 0.4868 - acc: 0.7646 - val_loss: 0.5054 - val_acc: 0.7402\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s - loss: 0.4693 - acc: 0.7763 - val_loss: 0.5059 - val_acc: 0.7717\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s - loss: 0.4708 - acc: 0.7724 - val_loss: 0.5027 - val_acc: 0.7717\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s - loss: 0.4678 - acc: 0.7782 - val_loss: 0.5011 - val_acc: 0.7717\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s - loss: 0.4664 - acc: 0.7840 - val_loss: 0.5009 - val_acc: 0.7598\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s - loss: 0.4698 - acc: 0.7782 - val_loss: 0.5018 - val_acc: 0.7835\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s - loss: 0.4694 - acc: 0.7802 - val_loss: 0.5050 - val_acc: 0.7520\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s - loss: 0.4642 - acc: 0.7743 - val_loss: 0.5051 - val_acc: 0.7638\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s - loss: 0.4694 - acc: 0.7782 - val_loss: 0.5015 - val_acc: 0.7756\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s - loss: 0.4747 - acc: 0.7685 - val_loss: 0.5036 - val_acc: 0.7520\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s - loss: 0.4680 - acc: 0.7821 - val_loss: 0.5011 - val_acc: 0.7677\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s - loss: 0.4736 - acc: 0.7743 - val_loss: 0.5040 - val_acc: 0.7520\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s - loss: 0.4690 - acc: 0.7724 - val_loss: 0.5071 - val_acc: 0.7598\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s - loss: 0.4696 - acc: 0.7899 - val_loss: 0.5087 - val_acc: 0.7323\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s - loss: 0.4776 - acc: 0.7821 - val_loss: 0.5014 - val_acc: 0.7677\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s - loss: 0.4655 - acc: 0.7626 - val_loss: 0.5032 - val_acc: 0.7559\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s - loss: 0.4664 - acc: 0.7704 - val_loss: 0.4985 - val_acc: 0.7520\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s - loss: 0.4676 - acc: 0.7763 - val_loss: 0.5030 - val_acc: 0.7598\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s - loss: 0.4650 - acc: 0.7860 - val_loss: 0.4979 - val_acc: 0.7598\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s - loss: 0.4694 - acc: 0.7899 - val_loss: 0.5035 - val_acc: 0.7480\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s - loss: 0.4628 - acc: 0.7743 - val_loss: 0.5094 - val_acc: 0.7638\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s - loss: 0.4936 - acc: 0.7529 - val_loss: 0.5126 - val_acc: 0.7520\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s - loss: 0.4635 - acc: 0.7724 - val_loss: 0.5007 - val_acc: 0.7480\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s - loss: 0.4563 - acc: 0.7802 - val_loss: 0.5075 - val_acc: 0.7323\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s - loss: 0.4620 - acc: 0.7685 - val_loss: 0.5087 - val_acc: 0.7677\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s - loss: 0.4577 - acc: 0.7860 - val_loss: 0.5028 - val_acc: 0.7559\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s - loss: 0.4550 - acc: 0.7782 - val_loss: 0.5059 - val_acc: 0.7677\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s - loss: 0.4664 - acc: 0.7724 - val_loss: 0.5051 - val_acc: 0.7362\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s - loss: 0.4585 - acc: 0.7782 - val_loss: 0.5249 - val_acc: 0.7598\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s - loss: 0.4767 - acc: 0.7704 - val_loss: 0.5056 - val_acc: 0.7441\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s - loss: 0.4555 - acc: 0.7763 - val_loss: 0.5072 - val_acc: 0.7756\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s - loss: 0.4583 - acc: 0.7802 - val_loss: 0.5033 - val_acc: 0.7480\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s - loss: 0.4515 - acc: 0.7899 - val_loss: 0.5029 - val_acc: 0.7559\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s - loss: 0.4561 - acc: 0.7802 - val_loss: 0.5086 - val_acc: 0.7480\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s - loss: 0.4613 - acc: 0.7665 - val_loss: 0.5159 - val_acc: 0.7756\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s - loss: 0.4532 - acc: 0.7840 - val_loss: 0.5075 - val_acc: 0.7362\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s - loss: 0.4497 - acc: 0.7646 - val_loss: 0.5091 - val_acc: 0.7756\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s - loss: 0.4633 - acc: 0.7646 - val_loss: 0.5052 - val_acc: 0.7677\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s - loss: 0.4515 - acc: 0.7802 - val_loss: 0.4978 - val_acc: 0.7795\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s - loss: 0.4474 - acc: 0.7782 - val_loss: 0.4994 - val_acc: 0.7480\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s - loss: 0.4512 - acc: 0.7782 - val_loss: 0.5025 - val_acc: 0.7717\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s - loss: 0.4521 - acc: 0.7685 - val_loss: 0.5029 - val_acc: 0.7756\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s - loss: 0.4473 - acc: 0.7899 - val_loss: 0.5028 - val_acc: 0.7362\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s - loss: 0.4460 - acc: 0.7782 - val_loss: 0.5011 - val_acc: 0.7835\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s - loss: 0.4491 - acc: 0.7821 - val_loss: 0.5048 - val_acc: 0.7362\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s - loss: 0.4455 - acc: 0.7918 - val_loss: 0.5006 - val_acc: 0.7323\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s - loss: 0.4464 - acc: 0.7743 - val_loss: 0.4979 - val_acc: 0.7559\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s - loss: 0.4453 - acc: 0.7840 - val_loss: 0.4970 - val_acc: 0.7559\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s - loss: 0.4452 - acc: 0.7879 - val_loss: 0.5060 - val_acc: 0.7717\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s - loss: 0.4445 - acc: 0.7957 - val_loss: 0.4995 - val_acc: 0.7598\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s - loss: 0.4513 - acc: 0.7802 - val_loss: 0.5014 - val_acc: 0.7677\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.4436 - acc: 0.7918 - val_loss: 0.5115 - val_acc: 0.7362\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s - loss: 0.4487 - acc: 0.7704 - val_loss: 0.5137 - val_acc: 0.7835\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s - loss: 0.4448 - acc: 0.7938 - val_loss: 0.5039 - val_acc: 0.7402\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s - loss: 0.4560 - acc: 0.7724 - val_loss: 0.5101 - val_acc: 0.7598\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s - loss: 0.4462 - acc: 0.7840 - val_loss: 0.5012 - val_acc: 0.7520\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s - loss: 0.4518 - acc: 0.7665 - val_loss: 0.5107 - val_acc: 0.7638\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s - loss: 0.4376 - acc: 0.7840 - val_loss: 0.5008 - val_acc: 0.7717\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s - loss: 0.4548 - acc: 0.7899 - val_loss: 0.5052 - val_acc: 0.7402\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s - loss: 0.4499 - acc: 0.7802 - val_loss: 0.4989 - val_acc: 0.7559\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s - loss: 0.4557 - acc: 0.7782 - val_loss: 0.5106 - val_acc: 0.7717\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s - loss: 0.4498 - acc: 0.7860 - val_loss: 0.5056 - val_acc: 0.7677\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s - loss: 0.4837 - acc: 0.7549 - val_loss: 0.5180 - val_acc: 0.7559\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s - loss: 0.4484 - acc: 0.7782 - val_loss: 0.5050 - val_acc: 0.7283\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s - loss: 0.4453 - acc: 0.7840 - val_loss: 0.5075 - val_acc: 0.7402\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s - loss: 0.4494 - acc: 0.7957 - val_loss: 0.5032 - val_acc: 0.7520\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s - loss: 0.4484 - acc: 0.7840 - val_loss: 0.5221 - val_acc: 0.7244\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s - loss: 0.4663 - acc: 0.7685 - val_loss: 0.5096 - val_acc: 0.7520\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s - loss: 0.4408 - acc: 0.7918 - val_loss: 0.5009 - val_acc: 0.7677\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s - loss: 0.4455 - acc: 0.7840 - val_loss: 0.5184 - val_acc: 0.7756\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s - loss: 0.4389 - acc: 0.7879 - val_loss: 0.5209 - val_acc: 0.7362\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s - loss: 0.4429 - acc: 0.7840 - val_loss: 0.5072 - val_acc: 0.7717\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s - loss: 0.4452 - acc: 0.7821 - val_loss: 0.5068 - val_acc: 0.7795\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s - loss: 0.4455 - acc: 0.7899 - val_loss: 0.5076 - val_acc: 0.7402\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s - loss: 0.4399 - acc: 0.7860 - val_loss: 0.4997 - val_acc: 0.7598\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s - loss: 0.4468 - acc: 0.7802 - val_loss: 0.5091 - val_acc: 0.7598\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s - loss: 0.4471 - acc: 0.7821 - val_loss: 0.5232 - val_acc: 0.7756\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s - loss: 0.4385 - acc: 0.7821 - val_loss: 0.5104 - val_acc: 0.7362\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s - loss: 0.4370 - acc: 0.7802 - val_loss: 0.5059 - val_acc: 0.7677\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s - loss: 0.4302 - acc: 0.7977 - val_loss: 0.5042 - val_acc: 0.7559\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s - loss: 0.4571 - acc: 0.7782 - val_loss: 0.5164 - val_acc: 0.7323\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s - loss: 0.4425 - acc: 0.7840 - val_loss: 0.5091 - val_acc: 0.7402\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s - loss: 0.4395 - acc: 0.7938 - val_loss: 0.5090 - val_acc: 0.7323\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s - loss: 0.4418 - acc: 0.7899 - val_loss: 0.5042 - val_acc: 0.7441\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s - loss: 0.4335 - acc: 0.7899 - val_loss: 0.4997 - val_acc: 0.7638\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s - loss: 0.4404 - acc: 0.7840 - val_loss: 0.5084 - val_acc: 0.7520\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s - loss: 0.4459 - acc: 0.7782 - val_loss: 0.5237 - val_acc: 0.7756\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s - loss: 0.4235 - acc: 0.7879 - val_loss: 0.5169 - val_acc: 0.7441\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s - loss: 0.4318 - acc: 0.7821 - val_loss: 0.5056 - val_acc: 0.7441\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s - loss: 0.4233 - acc: 0.7938 - val_loss: 0.5080 - val_acc: 0.7480\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s - loss: 0.4290 - acc: 0.7879 - val_loss: 0.5061 - val_acc: 0.7402\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s - loss: 0.4299 - acc: 0.7879 - val_loss: 0.5230 - val_acc: 0.7283\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s - loss: 0.4498 - acc: 0.7626 - val_loss: 0.5219 - val_acc: 0.7756\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s - loss: 0.4340 - acc: 0.7860 - val_loss: 0.5128 - val_acc: 0.7441\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s - loss: 0.4274 - acc: 0.7899 - val_loss: 0.5151 - val_acc: 0.7559\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s - loss: 0.4379 - acc: 0.7957 - val_loss: 0.5282 - val_acc: 0.7323\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s - loss: 0.4675 - acc: 0.7763 - val_loss: 0.5144 - val_acc: 0.7480\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s - loss: 0.4334 - acc: 0.7821 - val_loss: 0.5139 - val_acc: 0.7520\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s - loss: 0.4249 - acc: 0.7840 - val_loss: 0.5098 - val_acc: 0.7520\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s - loss: 0.4229 - acc: 0.7918 - val_loss: 0.5153 - val_acc: 0.7638\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s - loss: 0.4294 - acc: 0.8035 - val_loss: 0.5495 - val_acc: 0.7323\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s - loss: 0.4533 - acc: 0.7860 - val_loss: 0.5092 - val_acc: 0.7480\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s - loss: 0.4321 - acc: 0.7782 - val_loss: 0.5346 - val_acc: 0.7638\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s - loss: 0.4484 - acc: 0.7938 - val_loss: 0.5475 - val_acc: 0.7402\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s - loss: 0.4638 - acc: 0.7626 - val_loss: 0.5069 - val_acc: 0.7441\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s - loss: 0.4258 - acc: 0.7821 - val_loss: 0.5127 - val_acc: 0.7323\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s - loss: 0.4227 - acc: 0.7879 - val_loss: 0.5144 - val_acc: 0.7480\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s - loss: 0.4226 - acc: 0.7938 - val_loss: 0.5196 - val_acc: 0.7598\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s - loss: 0.4194 - acc: 0.7977 - val_loss: 0.5124 - val_acc: 0.7402\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s - loss: 0.4232 - acc: 0.7938 - val_loss: 0.5190 - val_acc: 0.7441\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s - loss: 0.4291 - acc: 0.7821 - val_loss: 0.5394 - val_acc: 0.7638\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s - loss: 0.4250 - acc: 0.7977 - val_loss: 0.5117 - val_acc: 0.7402\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s - loss: 0.4156 - acc: 0.8054 - val_loss: 0.5244 - val_acc: 0.7717\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s - loss: 0.4174 - acc: 0.8074 - val_loss: 0.5133 - val_acc: 0.7598\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s - loss: 0.4340 - acc: 0.7899 - val_loss: 0.5241 - val_acc: 0.7402\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s - loss: 0.4322 - acc: 0.7938 - val_loss: 0.5120 - val_acc: 0.7559\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s - loss: 0.4166 - acc: 0.7899 - val_loss: 0.5148 - val_acc: 0.7480\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s - loss: 0.4203 - acc: 0.7840 - val_loss: 0.5317 - val_acc: 0.7520\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s - loss: 0.4189 - acc: 0.7957 - val_loss: 0.5159 - val_acc: 0.7402\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s - loss: 0.4139 - acc: 0.7879 - val_loss: 0.5303 - val_acc: 0.7520\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s - loss: 0.4321 - acc: 0.7977 - val_loss: 0.5240 - val_acc: 0.7402\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s - loss: 0.4150 - acc: 0.8074 - val_loss: 0.5185 - val_acc: 0.7480\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s - loss: 0.4130 - acc: 0.7938 - val_loss: 0.5172 - val_acc: 0.7441\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s - loss: 0.4110 - acc: 0.8035 - val_loss: 0.5179 - val_acc: 0.7638\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s - loss: 0.4173 - acc: 0.7938 - val_loss: 0.5166 - val_acc: 0.7598\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s - loss: 0.4141 - acc: 0.7957 - val_loss: 0.5181 - val_acc: 0.7480\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s - loss: 0.4142 - acc: 0.7918 - val_loss: 0.5171 - val_acc: 0.7402\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s - loss: 0.4130 - acc: 0.8074 - val_loss: 0.5155 - val_acc: 0.7441\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s - loss: 0.4222 - acc: 0.8016 - val_loss: 0.5364 - val_acc: 0.7677\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s - loss: 0.4257 - acc: 0.8035 - val_loss: 0.5138 - val_acc: 0.7441\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s - loss: 0.4553 - acc: 0.7899 - val_loss: 0.5155 - val_acc: 0.7402\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s - loss: 0.4189 - acc: 0.7938 - val_loss: 0.5176 - val_acc: 0.7402\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s - loss: 0.4105 - acc: 0.8054 - val_loss: 0.5164 - val_acc: 0.7402\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s - loss: 0.4243 - acc: 0.7860 - val_loss: 0.5222 - val_acc: 0.7362\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s - loss: 0.4150 - acc: 0.7938 - val_loss: 0.5212 - val_acc: 0.7362\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s - loss: 0.4434 - acc: 0.7879 - val_loss: 0.5504 - val_acc: 0.7402\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s - loss: 0.4116 - acc: 0.8074 - val_loss: 0.5314 - val_acc: 0.7402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f712b1579b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/254 [==>...........................] - ETA: 0sacc: 74.02%\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(X_test,y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 79.22%\n",
      "acc: 75.32%\n",
      "acc: 72.73%\n",
      "acc: 85.71%\n",
      "acc: 81.82%\n",
      "acc: 77.92%\n",
      "acc: 68.83%\n",
      "acc: 75.32%\n",
      "acc: 69.74%\n",
      "acc: 80.26%\n",
      "76.69% (+/- 5.08%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True, random_state=seed)\n",
    "cvscores=[]\n",
    "for train,test in kfold.split(X,y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12,input_dim=8, kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(8,kernel_initializer='uniform',activation='relu'))  \n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid')) \n",
    "    # compile\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) \n",
    "    model.fit(X[train],y[train],epochs=150,batch_size=10,verbose=0)   \n",
    "    scores = model.evaluate(X[test],y[test],verbose=0)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1],scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\"%(np.mean(cvscores),np.std(cvscores)))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744771015557\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def create_model():\n",
    "    model =Sequential()\n",
    "    model.add(Dense(12, input_dim=8,kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "seed=7\n",
    "np.random.seed(seed)\n",
    "dataset = np.loadtxt('/home/tri/Downloads/MLdatasets/pima-indians-diabetes.data',delimiter=\",\")\n",
    "X=  dataset[:,0:8]\n",
    "y=dataset[:,8]\n",
    "model = KerasClassifier(build_fn=create_model,epochs=150, batch_size=10,verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True, random_state=seed)\n",
    "results= cross_val_score(model,X,y,cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 0.753906 using {'optimizer': 'adam', 'init': 'uniform', 'epochs': 150, 'batch_size': 10} \n",
      "0.635417 (0.093333) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 5}\n",
      "0.678385 (0.016053) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 5}\n",
      "0.720052 (0.007366) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 50, 'batch_size': 5}\n",
      "0.708333 (0.007366) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 50, 'batch_size': 5}\n",
      "0.710938 (0.019137) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 50, 'batch_size': 5}\n",
      "0.692708 (0.034987) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 50, 'batch_size': 5}\n",
      "0.683594 (0.022999) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 5}\n",
      "0.692708 (0.054718) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 5}\n",
      "0.717448 (0.021236) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 100, 'batch_size': 5}\n",
      "0.718750 (0.039192) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 100, 'batch_size': 5}\n",
      "0.723958 (0.027126) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 100, 'batch_size': 5}\n",
      "0.739583 (0.014731) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 100, 'batch_size': 5}\n",
      "0.673177 (0.015073) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 5}\n",
      "0.596354 (0.192488) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 5}\n",
      "0.736979 (0.026557) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 150, 'batch_size': 5}\n",
      "0.740885 (0.018688) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 150, 'batch_size': 5}\n",
      "0.717448 (0.026557) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 150, 'batch_size': 5}\n",
      "0.748698 (0.019488) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 150, 'batch_size': 5}\n",
      "0.651042 (0.040637) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 10}\n",
      "0.673177 (0.024360) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 10}\n",
      "0.705729 (0.013279) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 50, 'batch_size': 10}\n",
      "0.695312 (0.014616) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 50, 'batch_size': 10}\n",
      "0.683594 (0.027805) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 50, 'batch_size': 10}\n",
      "0.708333 (0.025582) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 50, 'batch_size': 10}\n",
      "0.680990 (0.012075) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 10}\n",
      "0.705729 (0.027866) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 10}\n",
      "0.723958 (0.006639) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 100, 'batch_size': 10}\n",
      "0.730469 (0.025315) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 100, 'batch_size': 10}\n",
      "0.736979 (0.011201) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 100, 'batch_size': 10}\n",
      "0.716146 (0.019488) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 100, 'batch_size': 10}\n",
      "0.718750 (0.041463) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 10}\n",
      "0.703125 (0.014616) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 10}\n",
      "0.721354 (0.024150) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 150, 'batch_size': 10}\n",
      "0.736979 (0.027126) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 150, 'batch_size': 10}\n",
      "0.699219 (0.031412) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 150, 'batch_size': 10}\n",
      "0.753906 (0.019401) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 150, 'batch_size': 10}\n",
      "0.687500 (0.008438) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 20}\n",
      "0.666667 (0.041626) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 50, 'batch_size': 20}\n",
      "0.667969 (0.016877) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 50, 'batch_size': 20}\n",
      "0.670573 (0.012890) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 50, 'batch_size': 20}\n",
      "0.695312 (0.014616) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 50, 'batch_size': 20}\n",
      "0.710938 (0.011049) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 50, 'batch_size': 20}\n",
      "0.683594 (0.019918) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 20}\n",
      "0.567708 (0.131362) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 100, 'batch_size': 20}\n",
      "0.691406 (0.013902) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 100, 'batch_size': 20}\n",
      "0.720052 (0.009744) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 100, 'batch_size': 20}\n",
      "0.710938 (0.008438) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 100, 'batch_size': 20}\n",
      "0.677083 (0.042473) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 100, 'batch_size': 20}\n",
      "0.701823 (0.020505) with: {'optimizer': 'rmsprop', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 20}\n",
      "0.574219 (0.177236) with: {'optimizer': 'adam', 'init': 'glorot_uniform', 'epochs': 150, 'batch_size': 20}\n",
      "0.739583 (0.025780) with: {'optimizer': 'rmsprop', 'init': 'normal', 'epochs': 150, 'batch_size': 20}\n",
      "0.722656 (0.028348) with: {'optimizer': 'adam', 'init': 'normal', 'epochs': 150, 'batch_size': 20}\n",
      "0.708333 (0.032734) with: {'optimizer': 'rmsprop', 'init': 'uniform', 'epochs': 150, 'batch_size': 20}\n",
      "0.704427 (0.033804) with: {'optimizer': 'adam', 'init': 'uniform', 'epochs': 150, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12,input_dim=8, kernel_initializer=init,activation='relu'))\n",
    "    model.add(Dense(8,kernel_initializer=init,activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init,activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model,epochs=150, batch_size=10,verbose=0)\n",
    "optimizers =['rmsprop','adam']\n",
    "init = ['glorot_uniform','normal','uniform']\n",
    "epochs =[50,100,150]\n",
    "batches = [5,10,20]\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs,batch_size=batches, init=init)\n",
    "\n",
    "grid = GridSearchCV(estimator=model,param_grid=param_grid)\n",
    "grid_result = grid.fit(X,y)\n",
    "print(\"Best %f using %s \" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means,stds,params):\n",
    "    print(\"%f (%f) with: %r\" % (mean,stdev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
