{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML real world problems are varied and may require some tailor to suit the need. In this tutorial, we exaplore an simple example to create a simple estimator [readme](http://scikit-learn.org/dev/developers/contributing.html#rolling-your-own-estimator).   \n",
    "1. At first, we need to choose one of these: __Classifier, Clusterring, Regressor and Transformer__. The classifier is self-explanatory, we give some input X and get the class of which it probably belongs (e.g. Naive Bayes Classifier). An example of Regressor is e.g. Linear Regression which get input X and get estimations of variable Y. Another example, Transformer, is for transforming the data -- it takes X and returns changed X. An example of this might be PCA.   \n",
    "2. After that we need to decide which one suits to our needs our subclass __BaseEstimator__ and an appropriate class for your type (one of ClassifierMixin, RegressorMixin, ClusterMixin, TransformerMixin).  \n",
    " [ExtraReading](http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/)  \n",
    " A custom sklearn  estimator consists of at least three methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An  __init__ initialization method   \n",
    "A __fit__ method to train the estimator   \n",
    "A __predict__ method to perform a prediction on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example, inherit from the classes BaseEstimator, ClassifierMixin\n",
    "class RidgeClassifier(BaseEstimator, ClassifierMixin):      \n",
    "       \n",
    "    def __init__(self,param1,param2):      \n",
    "        self.param1 = param1      \n",
    "        self.param2 = param2      \n",
    "    def fit(self, X, y=None):      \n",
    "        # do something   \n",
    "        return self   \n",
    "    def predict(self, X_test):   \n",
    "        # do something   \n",
    "        return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()\n",
    "new_feature_names = ['_'.join(e.split()) for e in bc.feature_names]\n",
    "\n",
    "X = pd.DataFrame(bc.data, columns =new_feature_names)\n",
    "y =bc.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state =7, stratify =y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RidgeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"A classifier made from Ridge Regression\"\"\"\n",
    "    def __init__(self, alpha=0):\n",
    "        self.alpha = alpha\n",
    "    def fit(self,X,y = None) :\n",
    "        # passalong the alpha parameter to theinernal ridge estimator and perform a fit using it\n",
    "        self.ridge_regressor = Ridge(alpha =self.alpha)\n",
    "        self.ridge_regressor.fit(X,y)\n",
    "          # save the seen class labels\n",
    "        self.class_labels =np.unique(y)   \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        # store the results of the internal ridge regressor estimator\n",
    "        results = self.ridge_regressor.predict(X_test)\n",
    "        # find the nearest class labels\n",
    "        \n",
    "        return np.array([self.class_labels[np.abs(self.class_labels - x).argmin()] for x in results])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a new classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95744680851063835"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_classifier = RidgeClassifier(1.5)\n",
    "r_classifier.fit(X_train, y_train)\n",
    "r_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excute hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00199978,  0.00200105,  0.00266838,  0.00133467,  0.00166138]),\n",
       " 'mean_score_time': array([ 0.00149965,  0.00133332,  0.00100048,  0.00066646,  0.00134802]),\n",
       " 'mean_test_score': array([ 0.94750656,  0.95800525,  0.96062992,  0.96062992,  0.96062992]),\n",
       " 'mean_train_score': array([ 0.96060881,  0.95142756,  0.95272442,  0.95403675,  0.95403675]),\n",
       " 'param_alpha': masked_array(data = [0 0.5 1.0 1.5 2.0],\n",
       "              mask = [False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'alpha': 0},\n",
       "  {'alpha': 0.5},\n",
       "  {'alpha': 1.0},\n",
       "  {'alpha': 1.5},\n",
       "  {'alpha': 2.0}],\n",
       " 'rank_test_score': array([5, 4, 1, 1, 1]),\n",
       " 'split0_test_score': array([ 0.953125,  0.96875 ,  0.96875 ,  0.96875 ,  0.96875 ]),\n",
       " 'split0_train_score': array([ 0.9486166 ,  0.94466403,  0.94071146,  0.94071146,  0.94071146]),\n",
       " 'split1_test_score': array([ 0.94488189,  0.96062992,  0.96850394,  0.96850394,  0.96850394]),\n",
       " 'split1_train_score': array([ 0.96850394,  0.95275591,  0.95275591,  0.95669291,  0.95669291]),\n",
       " 'split2_test_score': array([ 0.94444444,  0.94444444,  0.94444444,  0.94444444,  0.94444444]),\n",
       " 'split2_train_score': array([ 0.96470588,  0.95686275,  0.96470588,  0.96470588,  0.96470588]),\n",
       " 'std_fit_time': array([  4.09192288e-04,   1.87730977e-06,   2.01493821e-03,\n",
       "          2.36530537e-04,   2.26862959e-04]),\n",
       " 'std_score_time': array([  3.37174788e-07,   2.35741554e-04,   4.08705467e-04,\n",
       "          2.36135465e-04,   2.33461424e-04]),\n",
       " 'std_test_score': array([ 0.00400029,  0.01009447,  0.01137778,  0.01137778,  0.01137778]),\n",
       " 'std_train_score': array([ 0.00862037,  0.00506791,  0.00979571,  0.00997411,  0.00997411])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha':[0,0.5,1.0,1.5,2.0]}\n",
    "gs_rc = GridSearchCV(RidgeClassifier(), param_grid,cv =3).fit(X_train,y_train)\n",
    "\n",
    "gs_rc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95744680851063835"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# execute Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521276595744681"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a new classifier to work with sklearn from other packages\n",
    " The following problem is credited from [Scikitlearn_cookbook 2 edition]. There we use __general estimating equation__ (GEE) from [this](http://www.statsmodels.org/dev/gee.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GEEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" A Classifier made from statsmodels' Generalized Estimating Equations at http://www.statsmodels.org/dev/gee.html\"\"\"\n",
    "    def __init__(self, group_by_feature):\n",
    "        self.group_by_feature = group_by_feature\n",
    "        \n",
    "    def fit(self,X,y =None):\n",
    "        self.fam = sm.families.Poisson()\n",
    "        self.ind = sm.cov_struct.Exchangeable()\n",
    "        def expand_X(X,y,desired_group):\n",
    "            X_plus = X.copy()\n",
    "            X_plus['y'] = y\n",
    "            X_plus[desired_group+'group'] = (X_plus[desired_group] *10)//10\n",
    "            return X_plus\n",
    "        self.class_labels = np.unique(y)\n",
    "        dataframe_feature_names = X.columns\n",
    "        not_group_by_features =[x for x in dataframe_feature_names if x !=self.group_by_feature]\n",
    "        formula_in ='y~'+'+'.join(not_group_by_features)\n",
    "        data = expand_X(X,y, self.group_by_feature)\n",
    "        self.mod = smf.gee(formula_in,\n",
    "                          self.group_by_feature +\"_group\",\n",
    "                          data,\n",
    "                          cov_struct = self.ind,\n",
    "                          family = self.fam)\n",
    "        self.res = self.mod.fit()\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        results = self.res.predict(X_test)\n",
    "        return np.array([self.class_labels[np.abs(self.class_labels -x).argmin()] for x in results])\n",
    "    \n",
    "    def print_fit_summary(self):\n",
    "        print(res.summary())\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_concavity_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_concavity_group'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5b35d232c05c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgee_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGEEClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean_concavity'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgee_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgee_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-a778066f5d07>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m                           \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                           \u001b[0mcov_struct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                           family = self.fam)\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\generalized_estimating_equations.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, groups, data, subset, time, offset, exposure, *args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2442\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_concavity_group'"
     ]
    }
   ],
   "source": [
    "gee_classifier = GEEClassifier('mean_concavity')\n",
    "gee_classifier.fit(X_train, y_train)\n",
    "gee_classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.46</td>\n",
       "      <td>18.52</td>\n",
       "      <td>121.10</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.09874</td>\n",
       "      <td>0.10530</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.087950</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.06022</td>\n",
       "      <td>...</td>\n",
       "      <td>22.93</td>\n",
       "      <td>27.68</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.20890</td>\n",
       "      <td>0.31570</td>\n",
       "      <td>0.16420</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.08579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>12.18</td>\n",
       "      <td>14.08</td>\n",
       "      <td>77.25</td>\n",
       "      <td>461.4</td>\n",
       "      <td>0.07734</td>\n",
       "      <td>0.03212</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>...</td>\n",
       "      <td>12.85</td>\n",
       "      <td>16.47</td>\n",
       "      <td>81.60</td>\n",
       "      <td>513.1</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.05332</td>\n",
       "      <td>0.04116</td>\n",
       "      <td>0.01852</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>11.66</td>\n",
       "      <td>17.07</td>\n",
       "      <td>73.70</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.07561</td>\n",
       "      <td>0.03630</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.05731</td>\n",
       "      <td>...</td>\n",
       "      <td>13.28</td>\n",
       "      <td>19.74</td>\n",
       "      <td>83.61</td>\n",
       "      <td>542.5</td>\n",
       "      <td>0.09958</td>\n",
       "      <td>0.06476</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.04262</td>\n",
       "      <td>0.2731</td>\n",
       "      <td>0.06825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14.25</td>\n",
       "      <td>22.15</td>\n",
       "      <td>96.42</td>\n",
       "      <td>645.7</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.20080</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>0.086530</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.07292</td>\n",
       "      <td>...</td>\n",
       "      <td>17.67</td>\n",
       "      <td>29.51</td>\n",
       "      <td>119.10</td>\n",
       "      <td>959.5</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.62470</td>\n",
       "      <td>0.69220</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.11320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>11.15</td>\n",
       "      <td>13.08</td>\n",
       "      <td>70.87</td>\n",
       "      <td>381.9</td>\n",
       "      <td>0.09754</td>\n",
       "      <td>0.05113</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.06105</td>\n",
       "      <td>...</td>\n",
       "      <td>11.99</td>\n",
       "      <td>16.30</td>\n",
       "      <td>76.25</td>\n",
       "      <td>440.8</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>0.08971</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.05506</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.06772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "85         18.46         18.52          121.10     1075.0          0.09874   \n",
       "316        12.18         14.08           77.25      461.4          0.07734   \n",
       "350        11.66         17.07           73.70      421.0          0.07561   \n",
       "62         14.25         22.15           96.42      645.7          0.10490   \n",
       "153        11.15         13.08           70.87      381.9          0.09754   \n",
       "\n",
       "     mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "85            0.10530        0.133500             0.087950         0.2132   \n",
       "316           0.03212        0.011230             0.005051         0.1673   \n",
       "350           0.03630        0.008306             0.011620         0.1671   \n",
       "62            0.20080        0.213500             0.086530         0.1949   \n",
       "153           0.05113        0.019820             0.017860         0.1830   \n",
       "\n",
       "     mean_fractal_dimension           ...             worst_radius  \\\n",
       "85                  0.06022           ...                    22.93   \n",
       "316                 0.05649           ...                    12.85   \n",
       "350                 0.05731           ...                    13.28   \n",
       "62                  0.07292           ...                    17.67   \n",
       "153                 0.06105           ...                    11.99   \n",
       "\n",
       "     worst_texture  worst_perimeter  worst_area  worst_smoothness  \\\n",
       "85           27.68           152.20      1603.0           0.13980   \n",
       "316          16.47            81.60       513.1           0.10010   \n",
       "350          19.74            83.61       542.5           0.09958   \n",
       "62           29.51           119.10       959.5           0.16400   \n",
       "153          16.30            76.25       440.8           0.13410   \n",
       "\n",
       "     worst_compactness  worst_concavity  worst_concave_points  worst_symmetry  \\\n",
       "85             0.20890          0.31570               0.16420          0.3695   \n",
       "316            0.05332          0.04116               0.01852          0.2293   \n",
       "350            0.06476          0.03046               0.04262          0.2731   \n",
       "62             0.62470          0.69220               0.17850          0.2844   \n",
       "153            0.08971          0.07116               0.05506          0.2859   \n",
       "\n",
       "     worst_fractal_dimension  \n",
       "85                   0.08579  \n",
       "316                  0.06037  \n",
       "350                  0.06825  \n",
       "62                   0.11320  \n",
       "153                  0.06772  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Problem:** Create MeanClassifier. [from](http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>midterm</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>George</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellen</td>\n",
       "      <td>William</td>\n",
       "      <td>17.0</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Bush</td>\n",
       "      <td>17.0</td>\n",
       "      <td>m</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>Conan</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name   age  sex  midterm  Final\n",
       "0        Bob    George  18.0    f     89.0   91.0\n",
       "1      Ellen   William  17.0    m      NaN    NaN\n",
       "2        NaN       NaN   NaN  NaN      NaN   94.0\n",
       "3       Anna      Bush  17.0    m     87.0    NaN\n",
       "4       John     Conan  18.0    f     90.0   94.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = {'first_name': ['Bob','Ellen', np.nan, 'Anna', 'John'], \n",
    "        'last_name': ['George', 'William', np.nan,'Bush',  'Conan'], \n",
    "        'age': [18, 17, np.nan, 17, 18], \n",
    "        'sex': ['f', 'm',np.nan,  'm', 'f'], \n",
    "        'midterm': [ 89,np.nan, np.nan, 87, 90],\n",
    "        'Final': [91, np.nan,94, np.nan, 94]}\n",
    "df = pd.DataFrame(dat, columns = ['first_name', 'last_name', 'age', 'sex', 'midterm', 'Final'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before...\n",
      "  first_name last_name   age  sex  midterm  Final\n",
      "0        Bob    George  18.0    f     89.0   91.0\n",
      "1      Ellen   William  17.0    m      NaN    NaN\n",
      "2        NaN       NaN   NaN  NaN      NaN   94.0\n",
      "3       Anna      Bush  17.0    m     87.0    NaN\n",
      "4       John     Conan  18.0    f     90.0   94.0\n",
      "after...\n",
      "  first_name last_name   age sex    midterm  Final\n",
      "0        Bob    George  18.0   f  89.000000   91.0\n",
      "1      Ellen   William  17.0   m  88.666667   93.0\n",
      "2       Anna    George  17.5   f  88.666667   94.0\n",
      "3       Anna      Bush  17.0   m  87.000000   93.0\n",
      "4       John     Conan  18.0   f  90.000000   94.0\n"
     ]
    }
   ],
   "source": [
    "# scikit learn impute only process with numeric value, the following solution can solve this problem with category from\n",
    "# https://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        Columns of dtype object are imputed with the most frequent value in column.\n",
    "        Columns of other types are imputed with mean of column.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "#alternative, use data = [['a', 1, 2], []'b', 1, 1], ['b', 2, 2],[np.nan, np.nan, np.nan]]\n",
    "\n",
    "df_pre = DataFrameImputer().fit_transform(df)\n",
    "print('before...')\n",
    "print(df)\n",
    "print('after...')\n",
    "print(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
